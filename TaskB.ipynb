{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TaskB.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMod34J2yqEn7mEyMCDK4FY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ash95sv/AMLS_II_assignment19_20-/blob/master/TaskB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlStpCjYQBNM",
        "colab_type": "code",
        "outputId": "d2f0aa81-a6f6-4c42-929e-83f581923f66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import sys\n",
        "if 'google.colab' in sys.modules: # Colab-only Tensorflow version selector\n",
        "  %tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(\"Tensorflow version \" + tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version 2.2.0-rc3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kJUK_9M8TyZ",
        "colab_type": "code",
        "outputId": "0492515c-59e6-4740-a031-bdd84bd48e84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        }
      },
      "source": [
        "# Detect hardware, return appropriate distribution strategy\n",
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "    print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "    tpu = None\n",
        "    gpus = tf.config.experimental.list_logical_devices(\"GPU\")\n",
        "\n",
        "if tpu:\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "elif len(gpus) > 1: # multiple GPUs in one VM\n",
        "    strategy = tf.distribute.MirroredStrategy(gpus)\n",
        "else: # default strategy that works on CPU and single GPU\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "\n",
        "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on TPU  ['10.97.117.42:8470']\n",
            "INFO:tensorflow:Initializing the TPU system: grpc://10.97.117.42:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.97.117.42:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "REPLICAS:  8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16_NxbvV9Tpk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# batch and learning rate settings\n",
        "if strategy.num_replicas_in_sync == 8: # TPU or 8xGPU\n",
        "    BATCH_SIZE = 2 * strategy.num_replicas_in_sync\n",
        "elif strategy.num_replicas_in_sync == 1: # single GPU\n",
        "    BATCH_SIZE = 16\n",
        "else: # TPU pod\n",
        "    BATCH_SIZE = 8 * strategy.num_replicas_in_sync"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FR_Og2sO9Zrf",
        "colab_type": "code",
        "outputId": "6602a192-c6ee-4b6a-c6d0-b45c54f42b47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download() "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> d\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> stopwords\n",
            "    Downloading package stopwords to /root/nltk_data...\n",
            "      Package stopwords is already up-to-date!\n",
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> d\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> punkt\n",
            "    Downloading package punkt to /root/nltk_data...\n",
            "      Package punkt is already up-to-date!\n",
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> q\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeuyXxbg9dxg",
        "colab_type": "code",
        "outputId": "f3461357-cb28-4059-ee04-147c1a3eff12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_absolute_error, accuracy_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from matplotlib import pyplot\n",
        "\n",
        "import spacy \n",
        "#import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Input, Dropout, MaxPooling1D, Conv1D, GlobalMaxPool1D\n",
        "from tensorflow.keras.layers import LSTM, Lambda, Bidirectional, concatenate, BatchNormalization\n",
        "from tensorflow.keras.layers import TimeDistributed\n",
        "from tensorflow.keras.initializers import GlorotNormal\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\n",
        "\n",
        "import re\n",
        "import tensorflow.keras.callbacks\n",
        "import os\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from string import punctuation \n",
        "#import nltk\n",
        "#nltk.download('stopwords') \n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "\n",
        "def binarize(x, sz=72):\n",
        "    return tf.cast(tf.one_hot(x, sz, on_value=1, off_value=0, axis=-1),dtype=tf.float32)\n",
        "\n",
        "def binarize_outshape(in_shape, sz=72):\n",
        "    return in_shape[0], in_shape[1], sz\n",
        "\n",
        "\n",
        "def striphtml(s):\n",
        "    p = re.compile(r'<.*?>')\n",
        "    return p.sub('', s)\n",
        "\n",
        "\n",
        "def clean(s):\n",
        "    tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))', 'URL', s) # remove URLs\n",
        "    tweet = re.sub('@[^\\s]+', 'AT_USER', tweet) # remove usernames\n",
        "    tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet) # remove the # in #hashtag\n",
        "    #tweet = word_tokenize(tweet) # remove repeated characters (helloooooooo into hello)\n",
        "    return tweet\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_j5KVPg9kJY",
        "colab_type": "code",
        "outputId": "aeee6419-f0a0-467c-b5bf-c0eff9aebcd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#read the training data files\n",
        "df_train_2015 = pd.read_excel('twitter-2015train-BD.xls', names=('id', 'topic', 'label','tweet'), header=None)\n",
        "df_test_2015 = pd.read_excel('twitter-2015testBD.xls', names=('id', 'topic', 'label','tweet'),header=None)\n",
        "df_train_2016=pd.read_excel('twitter-2016train-BD.xls', names=('id', 'topic', 'label','tweet'),header=None)\n",
        "df_dev = pd.read_excel('twitter-2016dev-BD.xls', names=('id', 'topic', 'label','tweet'),header=None)\n",
        "df_devtest = pd.read_excel('twitter-2016devtest-BD.xls', names=('id', 'topic', 'label','tweet'),header=None)\n",
        "df_test_2016 = pd.read_excel('twitter-2016test-BD.xls', names=('id', 'topic', 'label','tweet'),header=None)\n",
        "#read the test data file\n",
        "df_test=pd.read_excel('SemEval2017-task4-test.subtask-BD.english.xls', names=('id', 'topic', 'label','tweet'),header=None)\n",
        "print(len(df_train_2015),len(df_test_2015),len(df_devtest),len(df_dev),len(df_train_2016),len(df_test_2016),len(df_test))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "489 2383 1417 1325 4346 10552 6185\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjlQ3OBk_Mmz",
        "colab_type": "code",
        "outputId": "442184fc-e6de-42a7-bdd0-2413036872e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df = pd.concat([df_train_2015,df_test_2015,df_train_2016,df_test_2016,df_dev,df_devtest])\n",
        "labels = df['label'].reset_index(drop=True) # label dataframe\n",
        "len(df)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20512"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIaYGFJe_jXc",
        "colab_type": "code",
        "outputId": "a7417bf1-21ab-4b1e-c9ea-1a7bda8141b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# remove neutral label, nan and off topics from df\n",
        "df = df[df.label != 'neutral']\n",
        "df = df[df.label != 'off topic']\n",
        "df.drop_duplicates(inplace=True)\n",
        "df.dropna(inplace=True)\n",
        "len(df)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18964"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVfxXP9QAILV",
        "colab_type": "code",
        "outputId": "21b9f6f0-c033-40a2-9224-9bece845cfb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "#describe the distribution of labels \n",
        "df.groupby('label').describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"4\" halign=\"left\">id</th>\n",
              "      <th colspan=\"4\" halign=\"left\">topic</th>\n",
              "      <th colspan=\"4\" halign=\"left\">tweet</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>unique</th>\n",
              "      <th>top</th>\n",
              "      <th>freq</th>\n",
              "      <th>count</th>\n",
              "      <th>unique</th>\n",
              "      <th>top</th>\n",
              "      <th>freq</th>\n",
              "      <th>count</th>\n",
              "      <th>unique</th>\n",
              "      <th>top</th>\n",
              "      <th>freq</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>negative</th>\n",
              "      <td>4013</td>\n",
              "      <td>4000</td>\n",
              "      <td>681305332610678016</td>\n",
              "      <td>2</td>\n",
              "      <td>4013</td>\n",
              "      <td>307</td>\n",
              "      <td>boko haram</td>\n",
              "      <td>149</td>\n",
              "      <td>4013</td>\n",
              "      <td>4000</td>\n",
              "      <td>Okay so the White Sox suck, Rose and Kane may ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>positive</th>\n",
              "      <td>14951</td>\n",
              "      <td>14901</td>\n",
              "      <td>641587837863915008</td>\n",
              "      <td>2</td>\n",
              "      <td>14951</td>\n",
              "      <td>354</td>\n",
              "      <td>foo fighters</td>\n",
              "      <td>228</td>\n",
              "      <td>14951</td>\n",
              "      <td>14895</td>\n",
              "      <td>Go all Wednesday Adams on us with our gorgeous...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             id         ...                                              tweet     \n",
              "          count unique  ...                                                top freq\n",
              "label                   ...                                                        \n",
              "negative   4013   4000  ...  Okay so the White Sox suck, Rose and Kane may ...    2\n",
              "positive  14951  14901  ...  Go all Wednesday Adams on us with our gorgeous...    4\n",
              "\n",
              "[2 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnJXbSqSA1_r",
        "colab_type": "code",
        "outputId": "b8e4bfe2-5743-41fe-b41e-efdce002b715",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 702
        }
      },
      "source": [
        "#describe the description of topics\n",
        "df_topic = df.groupby('topic')\n",
        "df_topic.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"4\" halign=\"left\">id</th>\n",
              "      <th colspan=\"4\" halign=\"left\">label</th>\n",
              "      <th colspan=\"4\" halign=\"left\">tweet</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>unique</th>\n",
              "      <th>top</th>\n",
              "      <th>freq</th>\n",
              "      <th>count</th>\n",
              "      <th>unique</th>\n",
              "      <th>top</th>\n",
              "      <th>freq</th>\n",
              "      <th>count</th>\n",
              "      <th>unique</th>\n",
              "      <th>top</th>\n",
              "      <th>freq</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>topic</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>#dexter</th>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>100018263337078000</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>positive</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>Barely going to sleep after watching #dexter a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>@microsoft</th>\n",
              "      <td>80</td>\n",
              "      <td>80</td>\n",
              "      <td>640736865499217024</td>\n",
              "      <td>1</td>\n",
              "      <td>80</td>\n",
              "      <td>2</td>\n",
              "      <td>negative</td>\n",
              "      <td>46</td>\n",
              "      <td>80</td>\n",
              "      <td>80</td>\n",
              "      <td>@Microsoft - congratulations on the 20th Birth...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>a$ap rocky</th>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>264082200927031008</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>positive</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>@funfunfunfest is coming up this weekend!! We\\...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>aaron rodgers</th>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>104742390924972000</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>2</td>\n",
              "      <td>positive</td>\n",
              "      <td>13</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>Aaron Rodgers is really catching shit for the ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>aaron samuels</th>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>518244187398238016</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>negative</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>It's October 4th. Let's be real, Aaron Samuels...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>yougov</th>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>522387765896675008</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>positive</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>@MSmithsonPB  this is YouGov tomorrow they cou...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>younique</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>521416045865992000</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>positive</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>Looking for 3 people to join my Younique team ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zac brown band</th>\n",
              "      <td>113</td>\n",
              "      <td>113</td>\n",
              "      <td>635067660875771008</td>\n",
              "      <td>1</td>\n",
              "      <td>113</td>\n",
              "      <td>2</td>\n",
              "      <td>positive</td>\n",
              "      <td>110</td>\n",
              "      <td>113</td>\n",
              "      <td>113</td>\n",
              "      <td>Music at Citizens Bank Park continues with the...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zayn</th>\n",
              "      <td>117</td>\n",
              "      <td>117</td>\n",
              "      <td>637895248170065024</td>\n",
              "      <td>1</td>\n",
              "      <td>117</td>\n",
              "      <td>2</td>\n",
              "      <td>positive</td>\n",
              "      <td>107</td>\n",
              "      <td>117</td>\n",
              "      <td>117</td>\n",
              "      <td>I am still yet to see Zayn's full fledged smil...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zlatan</th>\n",
              "      <td>64</td>\n",
              "      <td>64</td>\n",
              "      <td>637711360416198016</td>\n",
              "      <td>1</td>\n",
              "      <td>64</td>\n",
              "      <td>2</td>\n",
              "      <td>positive</td>\n",
              "      <td>60</td>\n",
              "      <td>64</td>\n",
              "      <td>64</td>\n",
              "      <td>@MrTransferNewss @FootbaIISources considering ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>358 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  id  ... tweet\n",
              "               count  ...  freq\n",
              "topic                 ...      \n",
              "#dexter           12  ...     1\n",
              "@microsoft        80  ...     1\n",
              "a$ap rocky         7  ...     1\n",
              "aaron rodgers     16  ...     1\n",
              "aaron samuels      6  ...     1\n",
              "...              ...  ...   ...\n",
              "yougov             8  ...     1\n",
              "younique          10  ...     1\n",
              "zac brown band   113  ...     1\n",
              "zayn             117  ...     1\n",
              "zlatan            64  ...     1\n",
              "\n",
              "[358 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0TgrbqYCaN-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.replace({'label': {'positive': 1, 'negative': 0}},inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNK56wk_NB4c",
        "colab_type": "code",
        "outputId": "05f9fee5-a937-421d-f08b-8b4b928c54b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pd.unique(df.label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGklPwytqn9Z",
        "colab_type": "code",
        "outputId": "f94fa569-9981-4d96-8a31-b5a244cd780e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "df_test.replace({'label': {'positive': 1, 'negative': 0}},inplace=True)\n",
        "df_test.groupby('label').describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"8\" halign=\"left\">id</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3722.0</td>\n",
              "      <td>8.029570e+17</td>\n",
              "      <td>1.668298e+15</td>\n",
              "      <td>7.989028e+17</td>\n",
              "      <td>8.021943e+17</td>\n",
              "      <td>8.023660e+17</td>\n",
              "      <td>8.052354e+17</td>\n",
              "      <td>8.057249e+17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2463.0</td>\n",
              "      <td>8.026407e+17</td>\n",
              "      <td>1.469903e+15</td>\n",
              "      <td>7.990280e+17</td>\n",
              "      <td>8.021162e+17</td>\n",
              "      <td>8.022043e+17</td>\n",
              "      <td>8.023762e+17</td>\n",
              "      <td>8.057242e+17</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id                ...                            \n",
              "        count          mean  ...           75%           max\n",
              "label                        ...                            \n",
              "0      3722.0  8.029570e+17  ...  8.052354e+17  8.057249e+17\n",
              "1      2463.0  8.026407e+17  ...  8.023762e+17  8.057242e+17\n",
              "\n",
              "[2 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUo6PIYTyL2N",
        "colab_type": "code",
        "outputId": "b60689bc-613d-4f94-8e7f-5c34b1618ab4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df_test['label'].value_counts()[1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2463"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3ntLm2gDodI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Average Recall, F1 score and Accuracy for All Positive and All Negative baselines\n",
        "#data = {'True' : df_test['label']}\n",
        "df_base = pd.DataFrame(y_test, columns=['True'])\n",
        "df_base['all positive'] = 1.0\n",
        "df_base['all negative'] = 0.0\n",
        "df_base=df_base.reset_index(drop=True)\n",
        "df_base\n",
        "p_recall_1 = recall_score(df_base['True'], df_base['all positive'])\n",
        "n_recall_1 = 0.0\n",
        "p_recall_2 = recall_score(df_base['True'], df_base['all negative'])\n",
        "n_recall_2 = 1.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfszlA7kTgIT",
        "colab_type": "code",
        "outputId": "fd2082bd-4194-4cec-c48b-442d0af469da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(p_recall_1, n_recall_1, p_recall_2 , n_recall_2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0 0.0 0.0 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XtAG4zBTqik",
        "colab_type": "code",
        "outputId": "c7c9c532-acd6-4ad3-ae95-5b21f8e16edc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "avg_recall_p = (p_recall_1 + n_recall_1)/2\n",
        "avg_recall_n = (p_recall_2+n_recall_2)/2\n",
        "print(\"Average Recall B1: \", avg_recall_p)\n",
        "print(\"Average Recall B2: \", avg_recall_n)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average Recall B1:  0.5\n",
            "Average Recall B2:  0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvQDu_W4Twjc",
        "colab_type": "code",
        "outputId": "191875e6-0f5c-47a1-e27c-56fc4bb55a6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "C1 = confusion_matrix(df_base['True'],df_base['all positive'])\n",
        "C2 = confusion_matrix(df_base['True'],df_base['all negative'])\n",
        "print(C1)\n",
        "print(C2)\n",
        "p_prec_1 = C1[1][1]/(C1[1][1]+C1[0][1])\n",
        "n_prec_1 = 0\n",
        "p_prec_2 = 0\n",
        "n_prec_2 = C2[0][0]/(C2[1][0]+C2[0][0])\n",
        "prec_1 = (p_prec_1 + n_prec_1)/2\n",
        "prec_2 = (p_prec_2 + n_prec_2)/2\n",
        "print(\"Average Precision B1: \", prec_1)\n",
        "print(\"Average Precision B2: \", prec_2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[   0  786]\n",
            " [   0 3007]]\n",
            "[[ 786    0]\n",
            " [3007    0]]\n",
            "Average Precision B1:  0.39638808331136305\n",
            "Average Precision B2:  0.10361191668863697\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0oiUQ6J0V8v",
        "colab_type": "code",
        "outputId": "e803bf2d-0dd7-48d4-8b6f-1ad9359bf8c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def F1_score(r,p):\n",
        "  return 2*r*p/(r+p)\n",
        "\n",
        "F1_1 = F1_score(avg_recall_p,prec_1)\n",
        "F1_2 = F1_score(avg_recall_n,prec_2)\n",
        "print(\"F1 scores:\", F1_1,F1_2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 scores: 0.44220588235294117 0.17165319938851276\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pABvR9Tq02bx",
        "colab_type": "code",
        "outputId": "c92a7a27-3170-4b6f-c79a-ebaaab634a59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Acc_1=accuracy_score(df_base['True'],df_base['all positive'])\n",
        "Acc_2=accuracy_score(df_base['True'],df_base['all negative'])\n",
        "print(\"Accuracies: \", Acc_1, Acc_2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracies:  0.7927761666227261 0.20722383337727393\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4bjuvAYZ7dC",
        "colab_type": "code",
        "outputId": "4ca182ef-0436-43d3-a4b2-9b51b846c0ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y = df['label'].tolist()\n",
        "type(y)\n",
        "y[99]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30d2NToh1InZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CNN with entire tweet and topic #Character\n",
        "def pre_process(df):\n",
        "  df['combined']=df['tweet']+' '+df['topic']\n",
        "  txt = ''\n",
        "  docs = []\n",
        "  sentences = []\n",
        "  sentiments = []\n",
        "  tweets=[]\n",
        "  i=0\n",
        "  stop_words = set(stopwords.words('english') + list(punctuation) + ['at_user','url'])\n",
        "\n",
        "  '''for cont, sentiment in zip(df_train.combined, df_train.label):\n",
        "      #sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', clean(striphtml(cont)))\n",
        "      cont.lower()\n",
        "      tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))', 'URL', cont) # remove URLs\n",
        "      tweet = re.sub('@[^\\s]+', 'AT_USER', tweet) # remove usernames\n",
        "      tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet) # remove the # in #hashtag\n",
        "      tweet = word_tokenize(tweet)\n",
        "      docs.append(tweet)\n",
        "      sentiments.append(sentiment)'''\n",
        "  for cont, sentiment in zip(df.combined, df.label):\n",
        "      strip=striphtml(cont)\n",
        "      cleaned=clean(strip)\n",
        "      sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', cleaned)\n",
        "      sentences = [sent.lower() for sent in sentences]\n",
        "      sentences = [word_tokenize(sent) for sent in sentences]\n",
        "      sentence_fin =[]\n",
        "      for sent in sentences:\n",
        "          sentence_fin.append([word for word in sent if word not in stop_words])\n",
        "      docs.append(sentence_fin)\n",
        "      sentiments.append(sentiment)\n",
        "\n",
        "  print(docs[80:90])\n",
        "  #find max number of sentences.\n",
        "  i=0\n",
        "  max_i=0\n",
        "  for sent in docs:\n",
        "      i=0\n",
        "      for k in sent:\n",
        "          i=i+1\n",
        "      max_i=max(i,max_i)\n",
        "      if(i==max_i):\n",
        "          j_max=sent\n",
        "\n",
        "  #find max number of characters in a tweet\n",
        "  max_char=0\n",
        "  for doc in docs:\n",
        "      count=0\n",
        "      for sent in doc:\n",
        "          for word in sent:\n",
        "              for s in word:\n",
        "                  count+=1\n",
        "                  max_char=max(max_char,count)\n",
        "  print(max_char)\n",
        "  for doc in docs:\n",
        "      for sent in doc:\n",
        "          for word in sent:\n",
        "              for s in word:\n",
        "                  txt += s\n",
        "          \n",
        "  chars = set(txt)\n",
        "  print('total chars:', len(chars))\n",
        "  char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "  indices_char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "  maxlen = 140 \n",
        "  max_sentences = 10\n",
        "\n",
        "  X = np.ones((len(docs), max_sentences, maxlen), dtype=np.int64) * -1\n",
        "  y = np.array(sentiments)\n",
        "  max_j=0\n",
        "  for i, doc in enumerate(docs):\n",
        "      for j, sentence in enumerate(doc):\n",
        "          if j < max_sentences:\n",
        "              for word in sentence[-maxlen:]:\n",
        "                  for t, char in enumerate(word):\n",
        "                      X[i, j, (maxlen-1-t)] = char_indices[char]\n",
        "            \n",
        "  #ONE HOT ENCODING LABELS\n",
        "  #label_encoder = LabelEncoder()\n",
        "  #integer_category = label_encoder.fit_transform(df.label)\n",
        "  #y = sentiments\n",
        "  #shuffle X and y\n",
        "  ids = np.arange(len(X))\n",
        "  np.random.shuffle(ids)\n",
        "\n",
        "  # shuffle\n",
        "  X = X[ids]\n",
        "  y = y[ids]\n",
        "\n",
        "  print(\"Shape of X \", X.shape)\n",
        "  print(\"Shape of Y \", y.shape)\n",
        "  return X,y,chars, max_sentences, maxlen"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "El4lAvtL2HmO",
        "colab_type": "code",
        "outputId": "be5d92b4-8afb-47f5-eba9-354256c73cb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "X, y,chars, max_sentences, maxlen = pre_process(df)\n",
        "y[0:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[['beohner', \"''\", 'got', '98', 'wanted.\\\\', \"''\", 'fact', 'dow', '634', 'today', 'boehner', 'owns', 'every', 'point'], ['p2', 'fok', 'maddow', 'teaparty', 'boehner']], [['mt', 'boehner', 'asks', 'obama', 'move', 'speech', 'thurs', '||', 'forget', 'u', \"''\", 'w/o', 'u\\\\', \"''\"], ['tues', 'works'], ['boehner']], [['hide', 'country', 'clubs', 'u', 'want', 'boehner', 'reverserobocall.com', 'launching', 'soon', \"'m\", 'one', '1st', 'line', 'join'], ['launch', 'boehner']], [['yeah', 'bright', 'side', 'got', 'letter', 'boise', 'state', 'yesterday', 'boise', 'state']], [['boise', 'state', \"'s\", 'jerseys', 'game', 'saturday', 'sick'], ['wo', \"n't\", 'dissapointed'], ['boise', 'state']], [['got', '2', 'letters', 'today', 'one', 'wake', 'forest', 'university', 'boise', 'state', 'boise', 'state']], [['ideal', 'world', 'oregon', 'boise', 'state', 'win', 'sept', '3rd', 'give', 'power', 'pac', 'nw', 'goducks', 'boise', 'state']], [['night', 'dream', 'uga', 'beat', 'boise', 'state'], ['let', \"'s\", 'hope', 'comes', 'true', 'boise', 'state']], [['way', 'bolton', 'stubborn', 'talking', 'demanding', 'stupid', 'fee'], ['expecting', 'jim', 'sign', 'today'], ['bolton']], [['wish', 'bolton', 'tonight', 'bolton']]]\n",
            "135\n",
            "total chars: 51\n",
            "Shape of X  (18964, 10, 140)\n",
            "Shape of Y  (18964,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 0, 0, 1, 1, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k30Fpo0E2Xtf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(chars,max_sentences,maxlen):\n",
        "  filter_length = [5, 3, 3]\n",
        "  nb_filter = [8, 16, 16]\n",
        "  pool_length = 2\n",
        "  # document input\n",
        "  document = Input(shape=(max_sentences, maxlen), dtype='int64')\n",
        "  # sentence input\n",
        "  in_sentence = Input(shape=(maxlen,), dtype='int64')\n",
        "  # char indices to one hot matrix, 1D sequence to 2D \n",
        "  embedded = Lambda(binarize, output_shape=binarize_outshape)(in_sentence)\n",
        "  # embedded: encodes sentence\n",
        "  for i in range(len(nb_filter)):\n",
        "      embedded = Conv1D(filters=nb_filter[i],\n",
        "                        kernel_size=filter_length[i],\n",
        "                        padding='same',\n",
        "                        activation='relu',\n",
        "                        kernel_initializer='he_normal',\n",
        "                        strides=1)(embedded)\n",
        "\n",
        "      embedded = MaxPooling1D(pool_size=pool_length)(embedded)\n",
        "      embedded = Dropout(0.3)(embedded)\n",
        "\n",
        "\n",
        "  bi_lstm_sent = Bidirectional(LSTM(20, return_sequences=False, dropout=0.3, recurrent_dropout=0.3, implementation=0))(embedded)\n",
        "\n",
        "  # sent_encode = merge([forward_sent, backward_sent], mode='concat', concat_axis=-1)\n",
        "  sent_encode = Dropout(0.3)(bi_lstm_sent)\n",
        "  # sentence encoder\n",
        "  encoder = Model(inputs=in_sentence, outputs=sent_encode)\n",
        "  encoder.summary()\n",
        "\n",
        "  encoded = TimeDistributed(encoder)(document)\n",
        "  # encoded: sentences to bi-lstm for document encoding \n",
        "  b_lstm_doc = Bidirectional(LSTM(20, return_sequences=False, dropout=0.3, recurrent_dropout=0.3, implementation=0))(encoded)\n",
        "\n",
        "  output = Dropout(0.3)(b_lstm_doc)\n",
        "  output = Dense(20, activation='relu')(output)\n",
        "  output = Dropout(0.3)(output)\n",
        "  output = Dense(1, activation='sigmoid')(output)\n",
        "\n",
        "  model = Model(inputs=document, outputs=output)\n",
        "\n",
        "  model.summary()\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qll5S1-o2dIF",
        "colab_type": "code",
        "outputId": "f141221e-1217-4835-bceb-9b5fb5a3943e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "epochs=50\n",
        "optimizer = 'adam'\n",
        "\n",
        "with strategy.scope():\n",
        "  model = create_model(chars,max_sentences,maxlen)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`implementation=0` has been deprecated, and now defaults to `implementation=1`.Please update your layer call.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`implementation=0` has been deprecated, and now defaults to `implementation=1`.Please update your layer call.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         [(None, 140)]             0         \n",
            "_________________________________________________________________\n",
            "lambda_3 (Lambda)            (None, 140, 72)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_9 (Conv1D)            (None, 140, 8)            2888      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_9 (MaxPooling1 (None, 70, 8)             0         \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 70, 8)             0         \n",
            "_________________________________________________________________\n",
            "conv1d_10 (Conv1D)           (None, 70, 16)            400       \n",
            "_________________________________________________________________\n",
            "max_pooling1d_10 (MaxPooling (None, 35, 16)            0         \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 35, 16)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_11 (Conv1D)           (None, 35, 16)            784       \n",
            "_________________________________________________________________\n",
            "max_pooling1d_11 (MaxPooling (None, 17, 16)            0         \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 17, 16)            0         \n",
            "_________________________________________________________________\n",
            "bidirectional_6 (Bidirection (None, 40)                5920      \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 40)                0         \n",
            "=================================================================\n",
            "Total params: 9,992\n",
            "Trainable params: 9,992\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:`implementation=0` has been deprecated, and now defaults to `implementation=1`.Please update your layer call.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`implementation=0` has been deprecated, and now defaults to `implementation=1`.Please update your layer call.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_7 (InputLayer)         [(None, 10, 140)]         0         \n",
            "_________________________________________________________________\n",
            "time_distributed_3 (TimeDist (None, 10, 40)            9992      \n",
            "_________________________________________________________________\n",
            "bidirectional_7 (Bidirection (None, 40)                9760      \n",
            "_________________________________________________________________\n",
            "dropout_22 (Dropout)         (None, 40)                0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 20)                820       \n",
            "_________________________________________________________________\n",
            "dropout_23 (Dropout)         (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 21        \n",
            "=================================================================\n",
            "Total params: 20,593\n",
            "Trainable params: 20,593\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8dQesyi6FZc",
        "colab_type": "code",
        "outputId": "e0940c31-d0d0-4d43-de33-856307c6c7cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "checkpoint = ModelCheckpoint(\"model_semeval.h5\", monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "early = EarlyStopping(monitor='val_loss', mode='min', patience=5)\n",
        "callback = [checkpoint,early]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n",
        "X_train,X_val,y_train,y_val = train_test_split(X_train , y_train , test_size=0.25, random_state = 42)\n",
        "#model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs = epochs, batch_size=BATCH_SIZE, validation_data=(X_val, y_val),verbose = 1, callbacks = callback)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "712/712 [==============================] - ETA: 0s - loss: 0.5329 - accuracy: 0.7885\n",
            "Epoch 00001: val_loss improved from inf to 0.52194, saving model to model_semeval.h5\n",
            "712/712 [==============================] - 18s 25ms/step - loss: 0.5329 - accuracy: 0.7885 - val_loss: 0.5219 - val_accuracy: 0.7825\n",
            "Epoch 2/50\n",
            "712/712 [==============================] - ETA: 0s - loss: 0.5236 - accuracy: 0.7889\n",
            "Epoch 00002: val_loss improved from 0.52194 to 0.52187, saving model to model_semeval.h5\n",
            "712/712 [==============================] - 18s 25ms/step - loss: 0.5236 - accuracy: 0.7889 - val_loss: 0.5219 - val_accuracy: 0.7825\n",
            "Epoch 3/50\n",
            "712/712 [==============================] - ETA: 0s - loss: 0.5094 - accuracy: 0.7891\n",
            "Epoch 00003: val_loss improved from 0.52187 to 0.48830, saving model to model_semeval.h5\n",
            "712/712 [==============================] - 18s 25ms/step - loss: 0.5094 - accuracy: 0.7891 - val_loss: 0.4883 - val_accuracy: 0.7825\n",
            "Epoch 4/50\n",
            "712/712 [==============================] - ETA: 0s - loss: 0.4917 - accuracy: 0.7896\n",
            "Epoch 00004: val_loss improved from 0.48830 to 0.47144, saving model to model_semeval.h5\n",
            "712/712 [==============================] - 19s 26ms/step - loss: 0.4917 - accuracy: 0.7896 - val_loss: 0.4714 - val_accuracy: 0.7851\n",
            "Epoch 5/50\n",
            "711/712 [============================>.] - ETA: 0s - loss: 0.4805 - accuracy: 0.7913\n",
            "Epoch 00005: val_loss improved from 0.47144 to 0.46073, saving model to model_semeval.h5\n",
            "712/712 [==============================] - 18s 25ms/step - loss: 0.4800 - accuracy: 0.7913 - val_loss: 0.4607 - val_accuracy: 0.7883\n",
            "Epoch 6/50\n",
            "710/712 [============================>.] - ETA: 0s - loss: 0.4709 - accuracy: 0.7938\n",
            "Epoch 00006: val_loss improved from 0.46073 to 0.45597, saving model to model_semeval.h5\n",
            "712/712 [==============================] - 18s 25ms/step - loss: 0.4705 - accuracy: 0.7936 - val_loss: 0.4560 - val_accuracy: 0.8038\n",
            "Epoch 7/50\n",
            "709/712 [============================>.] - ETA: 0s - loss: 0.4649 - accuracy: 0.8017\n",
            "Epoch 00007: val_loss improved from 0.45597 to 0.44096, saving model to model_semeval.h5\n",
            "712/712 [==============================] - 18s 25ms/step - loss: 0.4643 - accuracy: 0.8019 - val_loss: 0.4410 - val_accuracy: 0.8110\n",
            "Epoch 8/50\n",
            "710/712 [============================>.] - ETA: 0s - loss: 0.4499 - accuracy: 0.8078\n",
            "Epoch 00008: val_loss improved from 0.44096 to 0.43518, saving model to model_semeval.h5\n",
            "712/712 [==============================] - 18s 25ms/step - loss: 0.4495 - accuracy: 0.8077 - val_loss: 0.4352 - val_accuracy: 0.8178\n",
            "Epoch 9/50\n",
            "712/712 [==============================] - ETA: 0s - loss: 0.4403 - accuracy: 0.8050\n",
            "Epoch 00009: val_loss did not improve from 0.43518\n",
            "712/712 [==============================] - 18s 25ms/step - loss: 0.4403 - accuracy: 0.8050 - val_loss: 0.4361 - val_accuracy: 0.8052\n",
            "Epoch 10/50\n",
            "709/712 [============================>.] - ETA: 0s - loss: 0.4426 - accuracy: 0.8115\n",
            "Epoch 00010: val_loss improved from 0.43518 to 0.42916, saving model to model_semeval.h5\n",
            "712/712 [==============================] - 18s 25ms/step - loss: 0.4421 - accuracy: 0.8116 - val_loss: 0.4292 - val_accuracy: 0.8170\n",
            "Epoch 11/50\n",
            "709/712 [============================>.] - ETA: 0s - loss: 0.4399 - accuracy: 0.8115\n",
            "Epoch 00011: val_loss did not improve from 0.42916\n",
            "712/712 [==============================] - 17s 24ms/step - loss: 0.4393 - accuracy: 0.8118 - val_loss: 0.4324 - val_accuracy: 0.8139\n",
            "Epoch 12/50\n",
            "711/712 [============================>.] - ETA: 0s - loss: 0.4329 - accuracy: 0.8144\n",
            "Epoch 00012: val_loss improved from 0.42916 to 0.42576, saving model to model_semeval.h5\n",
            "712/712 [==============================] - 17s 24ms/step - loss: 0.4323 - accuracy: 0.8145 - val_loss: 0.4258 - val_accuracy: 0.8302\n",
            "Epoch 13/50\n",
            "710/712 [============================>.] - ETA: 0s - loss: 0.4289 - accuracy: 0.8164\n",
            "Epoch 00013: val_loss improved from 0.42576 to 0.42404, saving model to model_semeval.h5\n",
            "712/712 [==============================] - 17s 24ms/step - loss: 0.4285 - accuracy: 0.8164 - val_loss: 0.4240 - val_accuracy: 0.8247\n",
            "Epoch 14/50\n",
            "711/712 [============================>.] - ETA: 0s - loss: 0.4280 - accuracy: 0.8133\n",
            "Epoch 00014: val_loss improved from 0.42404 to 0.42177, saving model to model_semeval.h5\n",
            "712/712 [==============================] - 18s 25ms/step - loss: 0.4274 - accuracy: 0.8133 - val_loss: 0.4218 - val_accuracy: 0.8252\n",
            "Epoch 15/50\n",
            "711/712 [============================>.] - ETA: 0s - loss: 0.4267 - accuracy: 0.8168\n",
            "Epoch 00015: val_loss improved from 0.42177 to 0.42122, saving model to model_semeval.h5\n",
            "712/712 [==============================] - 19s 26ms/step - loss: 0.4261 - accuracy: 0.8168 - val_loss: 0.4212 - val_accuracy: 0.8276\n",
            "Epoch 16/50\n",
            "710/712 [============================>.] - ETA: 0s - loss: 0.4217 - accuracy: 0.8220\n",
            "Epoch 00016: val_loss improved from 0.42122 to 0.42066, saving model to model_semeval.h5\n",
            "712/712 [==============================] - 18s 25ms/step - loss: 0.4213 - accuracy: 0.8221 - val_loss: 0.4207 - val_accuracy: 0.8257\n",
            "Epoch 17/50\n",
            "709/712 [============================>.] - ETA: 0s - loss: 0.4229 - accuracy: 0.8187\n",
            "Epoch 00017: val_loss improved from 0.42066 to 0.41789, saving model to model_semeval.h5\n",
            "712/712 [==============================] - 18s 25ms/step - loss: 0.4221 - accuracy: 0.8190 - val_loss: 0.4179 - val_accuracy: 0.8294\n",
            "Epoch 18/50\n",
            "712/712 [==============================] - ETA: 0s - loss: 0.4238 - accuracy: 0.8217\n",
            "Epoch 00018: val_loss improved from 0.41789 to 0.41504, saving model to model_semeval.h5\n",
            "712/712 [==============================] - 18s 25ms/step - loss: 0.4238 - accuracy: 0.8217 - val_loss: 0.4150 - val_accuracy: 0.8318\n",
            "Epoch 19/50\n",
            "711/712 [============================>.] - ETA: 0s - loss: 0.4120 - accuracy: 0.8292\n",
            "Epoch 00019: val_loss did not improve from 0.41504\n",
            "712/712 [==============================] - 18s 25ms/step - loss: 0.4119 - accuracy: 0.8291 - val_loss: 0.4163 - val_accuracy: 0.8352\n",
            "Epoch 20/50\n",
            "712/712 [==============================] - ETA: 0s - loss: 0.4185 - accuracy: 0.8273\n",
            "Epoch 00020: val_loss improved from 0.41504 to 0.41303, saving model to model_semeval.h5\n",
            "712/712 [==============================] - 17s 24ms/step - loss: 0.4185 - accuracy: 0.8273 - val_loss: 0.4130 - val_accuracy: 0.8392\n",
            "Epoch 21/50\n",
            "711/712 [============================>.] - ETA: 0s - loss: 0.4163 - accuracy: 0.8266\n",
            "Epoch 00021: val_loss improved from 0.41303 to 0.41038, saving model to model_semeval.h5\n",
            "712/712 [==============================] - 18s 25ms/step - loss: 0.4158 - accuracy: 0.8266 - val_loss: 0.4104 - val_accuracy: 0.8368\n",
            "Epoch 22/50\n",
            "709/712 [============================>.] - ETA: 0s - loss: 0.4126 - accuracy: 0.8285\n",
            "Epoch 00022: val_loss did not improve from 0.41038\n",
            "712/712 [==============================] - 20s 28ms/step - loss: 0.4120 - accuracy: 0.8284 - val_loss: 0.4112 - val_accuracy: 0.8379\n",
            "Epoch 23/50\n",
            "712/712 [==============================] - ETA: 0s - loss: 0.4120 - accuracy: 0.8262\n",
            "Epoch 00023: val_loss improved from 0.41038 to 0.40936, saving model to model_semeval.h5\n",
            "712/712 [==============================] - 18s 25ms/step - loss: 0.4120 - accuracy: 0.8262 - val_loss: 0.4094 - val_accuracy: 0.8392\n",
            "Epoch 24/50\n",
            "711/712 [============================>.] - ETA: 0s - loss: 0.4077 - accuracy: 0.8261\n",
            "Epoch 00024: val_loss did not improve from 0.40936\n",
            "712/712 [==============================] - 17s 24ms/step - loss: 0.4072 - accuracy: 0.8262 - val_loss: 0.4149 - val_accuracy: 0.8286\n",
            "Epoch 25/50\n",
            "712/712 [==============================] - ETA: 0s - loss: 0.4076 - accuracy: 0.8281\n",
            "Epoch 00025: val_loss did not improve from 0.40936\n",
            "712/712 [==============================] - 18s 25ms/step - loss: 0.4076 - accuracy: 0.8281 - val_loss: 0.4119 - val_accuracy: 0.8350\n",
            "Epoch 26/50\n",
            "710/712 [============================>.] - ETA: 0s - loss: 0.4072 - accuracy: 0.8312\n",
            "Epoch 00026: val_loss did not improve from 0.40936\n",
            "712/712 [==============================] - 17s 24ms/step - loss: 0.4069 - accuracy: 0.8313 - val_loss: 0.4096 - val_accuracy: 0.8299\n",
            "Epoch 27/50\n",
            "709/712 [============================>.] - ETA: 0s - loss: 0.4060 - accuracy: 0.8300\n",
            "Epoch 00027: val_loss improved from 0.40936 to 0.40837, saving model to model_semeval.h5\n",
            "712/712 [==============================] - 17s 24ms/step - loss: 0.4054 - accuracy: 0.8300 - val_loss: 0.4084 - val_accuracy: 0.8379\n",
            "Epoch 28/50\n",
            "709/712 [============================>.] - ETA: 0s - loss: 0.4053 - accuracy: 0.8314\n",
            "Epoch 00028: val_loss did not improve from 0.40837\n",
            "712/712 [==============================] - 18s 25ms/step - loss: 0.4046 - accuracy: 0.8313 - val_loss: 0.4122 - val_accuracy: 0.8384\n",
            "Epoch 29/50\n",
            "711/712 [============================>.] - ETA: 0s - loss: 0.4037 - accuracy: 0.8338\n",
            "Epoch 00029: val_loss improved from 0.40837 to 0.40652, saving model to model_semeval.h5\n",
            "712/712 [==============================] - 17s 24ms/step - loss: 0.4032 - accuracy: 0.8338 - val_loss: 0.4065 - val_accuracy: 0.8397\n",
            "Epoch 30/50\n",
            "709/712 [============================>.] - ETA: 0s - loss: 0.4025 - accuracy: 0.8320\n",
            "Epoch 00030: val_loss did not improve from 0.40652\n",
            "712/712 [==============================] - 17s 24ms/step - loss: 0.4020 - accuracy: 0.8322 - val_loss: 0.4070 - val_accuracy: 0.8379\n",
            "Epoch 31/50\n",
            "710/712 [============================>.] - ETA: 0s - loss: 0.4040 - accuracy: 0.8341\n",
            "Epoch 00031: val_loss did not improve from 0.40652\n",
            "712/712 [==============================] - 17s 24ms/step - loss: 0.4034 - accuracy: 0.8342 - val_loss: 0.4088 - val_accuracy: 0.8397\n",
            "Epoch 32/50\n",
            "711/712 [============================>.] - ETA: 0s - loss: 0.4014 - accuracy: 0.8338\n",
            "Epoch 00032: val_loss improved from 0.40652 to 0.40498, saving model to model_semeval.h5\n",
            "712/712 [==============================] - 17s 25ms/step - loss: 0.4009 - accuracy: 0.8338 - val_loss: 0.4050 - val_accuracy: 0.8389\n",
            "Epoch 33/50\n",
            "712/712 [==============================] - ETA: 0s - loss: 0.3995 - accuracy: 0.8283\n",
            "Epoch 00033: val_loss improved from 0.40498 to 0.40212, saving model to model_semeval.h5\n",
            "712/712 [==============================] - 18s 25ms/step - loss: 0.3995 - accuracy: 0.8283 - val_loss: 0.4021 - val_accuracy: 0.8426\n",
            "Epoch 34/50\n",
            "711/712 [============================>.] - ETA: 0s - loss: 0.3985 - accuracy: 0.8339\n",
            "Epoch 00034: val_loss did not improve from 0.40212\n",
            "712/712 [==============================] - 17s 24ms/step - loss: 0.3981 - accuracy: 0.8339 - val_loss: 0.4044 - val_accuracy: 0.8373\n",
            "Epoch 35/50\n",
            "712/712 [==============================] - ETA: 0s - loss: 0.3959 - accuracy: 0.8313\n",
            "Epoch 00035: val_loss did not improve from 0.40212\n",
            "712/712 [==============================] - 17s 24ms/step - loss: 0.3959 - accuracy: 0.8313 - val_loss: 0.4158 - val_accuracy: 0.8373\n",
            "Epoch 36/50\n",
            "709/712 [============================>.] - ETA: 0s - loss: 0.4017 - accuracy: 0.8292\n",
            "Epoch 00036: val_loss did not improve from 0.40212\n",
            "712/712 [==============================] - 17s 25ms/step - loss: 0.4008 - accuracy: 0.8294 - val_loss: 0.4069 - val_accuracy: 0.8373\n",
            "Epoch 37/50\n",
            "712/712 [==============================] - ETA: 0s - loss: 0.4002 - accuracy: 0.8313\n",
            "Epoch 00037: val_loss did not improve from 0.40212\n",
            "712/712 [==============================] - 17s 24ms/step - loss: 0.4002 - accuracy: 0.8313 - val_loss: 0.4026 - val_accuracy: 0.8384\n",
            "Epoch 38/50\n",
            "709/712 [============================>.] - ETA: 0s - loss: 0.3912 - accuracy: 0.8326\n",
            "Epoch 00038: val_loss did not improve from 0.40212\n",
            "712/712 [==============================] - 17s 24ms/step - loss: 0.3910 - accuracy: 0.8322 - val_loss: 0.4066 - val_accuracy: 0.8321\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVH844rkh_9X",
        "colab_type": "code",
        "outputId": "05395aad-7069-4288-d82b-751099e7726f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "pyplot.plot(history.history['loss'])\n",
        "pyplot.plot(history.history['val_loss'])\n",
        "pyplot.title('model train vs validation loss')\n",
        "pyplot.ylabel('loss')\n",
        "pyplot.xlabel('epoch')\n",
        "pyplot.legend(['train', 'validation'], loc='upper right')\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4Dqz9H52h7J",
        "colab_type": "code",
        "outputId": "f11539d6-4343-4596-a47d-a2c7db0fc1b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#X_test,y_test,a,b,c=pre_process(df_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "129\n",
            "total chars: 51\n",
            "Shape of X  (6185, 10, 140)\n",
            "Shape of Y  (6185,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDO6INkLiLaH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_t, X_test, y_t, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMZnOHXNJvK6",
        "colab_type": "code",
        "outputId": "3e4c7078-61e8-4bc3-ac97-7451513abc9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "predictions = model.predict(X_test, batch_size = BATCH_SIZE, verbose = 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "238/238 [==============================] - 2s 7ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8w_cpH0ZFtD",
        "colab_type": "code",
        "outputId": "52c83ddf-e9d8-434d-ec0d-63062c5befaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "predictions.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3800, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erCuWIvIVi3R",
        "colab_type": "code",
        "outputId": "bc794eee-4399-4e0b-d818-69d0b9d98178",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pred=(predictions[0:3793] > 0.5).astype(np.uint8)\n",
        "accuracy_score(y_test,pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8426047983126812"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    }
  ]
}